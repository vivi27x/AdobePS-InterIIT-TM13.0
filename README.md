# InterIIT-Adobe-PS

**Detection of AI-Generated Images and Artifact Analysis**

Inter IIT Tech Meet 13.0 – Indian Institute of Technology, Kanpur

---

This repository presents our solutions to the Adobe Problem Statement at Inter IIT Tech Meet 13.0, focusing on two major tasks:

- **Detecting AI-generated images**
- **Predicting and explaining artifacts in AI-generated images**

For detailed instructions on running the code, please refer to the README files inside the `AI Generated Image Detection` and `Artifact Prediction and Explanation` folders.

For comprehensive documentation, including literature review, methodology, experimentation, and results, see the `ProjectReport.pdf`.

---

## Project Highlights

**1. AI-Generated Image Detection**

- Tackles the challenge of distinguishing real from AI-generated images, especially with advanced models like Stable Diffusion 3.5, Adobe Firefly, and GigaGAN.
- Developed a robust, generalizable detection pipeline using a quantized Binary Neural Network (BNN) approach (Faster Than Lies with BNext-Tiny backbone).
- Achieved **97% accuracy on CIFAKE** and **91% accuracy on curated white-box perturbation datasets**, with inference times suitable for on-device deployment.
- Explored and compared multiple detection strategies, including frequency domain analysis, CNNs, CLIP-based models, and adversarial robustness.
- Quantization techniques were applied to optimize model size and speed, balancing accuracy and deployment feasibility[^1].

**2. Artifact Prediction \& Explanation**

- Addressed the need for not just detecting AI-generated images but also explaining the presence of specific artifacts, enhancing transparency and trust in detection systems.
- Developed a multi-stage pipeline:
    - **Classifies images** into CIFAR-10 categories using DINOv2 features and SVM.
    - **Detects artifacts** via a combination of artifact-specific CNNs, JINA-CLIP-V2 similarity scoring, and a custom ensemble algorithm.
    - **Generates explanations** for detected artifacts using the Ovis-1.6 Gemma-9B Vision-Language Model (VLM), with carefully engineered prompts for detailed, context-specific outputs.
- Pipeline achieves a best IoU of 0.182 on the annotated dataset, with robust qualitative explanations for each artifact[^1].

---

## Key Results

| Model/Method | CIFAKE Accuracy | Curated Dataset Accuracy | Inference Time (ms) | Model Size (MB) |
| :-- | :-- | :-- | :-- | :-- |
| ResNet50 | 97.08% | 52% (Firefly/PixArt) | 2 | 92 |
| Aeroblade | 60.12% | - | 120 | 552 |
| FTL (BNN, ours) | 97.38% | 94% | 80 | 342 |
| Quantized FTL (ours) | 97% | 92% | 30 | 115 |

- Artifact detection pipeline combines CNNs, CLIP, and SVM, with explanations generated by VLMs for each artifact.
- Example explanations are highly descriptive, referencing specific image features and deviations from realism[^1].

---

## Usage

- **How to Run:**
    - See `AI Generated Image Detection/README.md` for detection pipeline instructions.
    - See `Artifact Prediction and Explanation/README.md` for artifact prediction and explanation pipeline instructions.
- **Full Project Details:**
    - Refer to `ProjectReport.pdf` for literature review, methodology, experiments, and in-depth discussion of results.

---

## Acknowledgements

We're immensely grateful to the Science & Technology Council, IIT Kanpur for their unwavering support throughout this process.

---

For any queries or further clarifications, please refer to the Project Report or raise an issue in this repository.

---

**Note:**

- For technical and implementation details, consult the inner READMEs.
- For theoretical background, experimental setup, and results, see the Project Report[^1].

---

[^1]

<div style="text-align: center">⁂</div>

[^1]: ProjectReport.pdf

[^2]: image.jpg
